<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos-7下常见中间件环境的安装（三）]]></title>
    <url>%2Fposts%2F3335490502%2F</url>
    <content type="text"><![CDATA[接着上篇文章，现在开始部署Redis集群，采用方案为四主四从，暂时不考虑搭建哨兵，因此需要八台机器，以下是部署过程中的一些记录。 准备工作集群机器信息 IP CPU、RAM 10.100.1.31 16 vcpu、64G ram 10.100.1.32 16 vcpu、64G ram 10.100.1.33 16 vcpu、64G ram 10.100.1.34 16 vcpu、64G ram 10.100.1.35 16 vcpu、64G ram 10.100.1.36 16 vcpu、64G ram 10.100.1.37 16 vcpu、64G ram 10.100.1.38 16 vcpu、64G ram Redis 为内存数据库，因此机器内存必须较大，根据经验，Redis占用内存一般不能超过机器内存的一半，不否则Redis的性能就会开始下降 Redis编译由于Redis并不能通过包管理工具（例如 yum、apt-get等）进行快速安装，只能下载源码进行编译安装。 12345jobshen@JobShen-PC:/usr/local$ curl -O http://download.redis.io/releases/redis-4.0.6.tar.gzjobshen@JobShen-PC:/usr/local$ tar -zxf redis-4.0.6.tar.gzjobshen@JobShen-PC:/usr/local$ ln -s redis-4.0.6 redisjobshen@JobShen-PC:/usr/local$ cd redisjobshen@JobShen-PC:/usr/local/redis$ make &amp;&amp; make install Redis Cluster 部署Redis.conf新建cluster文件夹，以及新建redis.conf文件并添加以下内容： 12jobshen@JobShen-PC:/usr/local/redis$ mkdir clusterjobshen@JobShen-PC:/usr/local/redis$ vim cluster/redis.conf 123456789101112131415161718192021bind 10.100.1.31 127.0.0.1protected-mode yesport 6379daemonize yessupervised systemdpidfile /var/run/redis_6379.pidlogfile &quot;/usr/local/redis/cluster/redis.log&quot;databases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesdbfilename dump.rdbslave-serve-stale-data yesslave-read-only yesslave-priority 100maxmemory 34359738368appendonly yescluster-enabled yescluster-config-file nodes-6379.confcluster-node-timeout 15000 Redis.service创建systemd服务， 1jobshen@JobShen-PC:/usr/local/redis$ vim /lib/systemd/system/redis.service 12345678910[Unit]Description=RedisAfter=network.target[Service]ExecStart=/usr/local/redis/src/redis-server /usr/local/redis/cluster/redis.conf --daemonize noExecStop=/usr/local/redis/src/redis-cli -h 127.0.0.1 -p 6379 shutdown[Install]WantedBy=multi-user.target 启动Redis1jobshen@JobShen-PC:/usr/local/redis$ systemctl start redis 创建Redis集群以下命令可以只在一台机器上执行，但为了后期维护Redis集群方便，可以在所有redis机器上都安装集群管理工具。 123456jobshen@JobShen-PC:/usr/local/redis$ gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDBjobshen@JobShen-PC:/usr/local/redis$ curl -sSL https://get.rvm.io | bash -s stablejobshen@JobShen-PC:/usr/local/redis$ rvm install 2.4.3jobshen@JobShen-PC:/usr/local/redis$ rvm use 2.4.3 --default --createjobshen@JobShen-PC:/usr/local/redis$ gem install redisjobshen@JobShen-PC:/usr/local/redis$ ./src/redis-trib.rb create --replicas 1 10.100.1.31:6379 10.100.1.32:6379 10.100.1.33:6379 10.100.1.34:6379 10.100.1.35:6379 10.100.1.36:6379 10.100.1.37:6379 10.100.1.38:6379 验证登入任意一台redis，查看集群信息 1234567891011jobshen@JobShen-PC:/usr/local/redis$ ./src/redis-cli -c -p 6369127.0.0.1:6379&gt; cluster nodes31f29a40699e44ae9b0dce5c8ded53cc92546c7f 10.100.1.31:6379@16379 master - 0 1513599855000 2 connected 4096-8191bd148fc244c821f0ebc502e2ef80e90e3ce8020f 10.100.1.32:6379@16379 master - 0 1513599857582 4 connected 12288-1638324c0c11cceb08a0a2c0f76773a1c3ecb5553fdd1 10.100.1.33:6379@16379 slave bd148fc244c821f0ebc502e2ef80e90e3ce8020f 0 1513599857000 8 connectedb8ed99aef612d728f69015b20dae32751af5a668 10.100.1.34:6379@16379 myself,master - 0 1513599854000 1 connected 0-4095ee420f56a64c89c519c82adf2131724456656711 10.100.1.35:6379@16379 slave b8ed99aef612d728f69015b20dae32751af5a668 0 1513599856000 5 connectedfa8f3b33ed93a8bb76c3f44b410436f12ca45d8c 10.100.1.36:6379@16379 slave 914483a3760cc5f7fc4422ea3326f39b0fc505b4 0 1513599854000 7 connected914483a3760cc5f7fc4422ea3326f39b0fc505b4 10.100.1.37:6379@16379 master - 0 1513599854000 3 connected 8192-12287da57f16f2f5b86cae95478157723c9b2972d460d 10.100.1.38:6379@16379 slave 31f29a40699e44ae9b0dce5c8ded53cc92546c7f 0 1513599854000 6 connected127.0.0.1:6379&gt; 到现在为止，整个Redis集群的搭建就完成了。]]></content>
      <tags>
        <tag>Redis</tag>
        <tag>Redis Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos-7下常见中间件环境的安装（二）]]></title>
    <url>%2Fposts%2F2345740436%2F</url>
    <content type="text"><![CDATA[接着上篇文章，现在开始部署RocketMQ集群，采用的部署方案是阿里推荐的两主两从异步刷盘的模式，因此准备了四台服务器来进行MQ集群的部署，以下是部署过程中的一些记录， 准备工作集群机器信息 IP CPU、RAM 作用 10.100.1.21 16 vcpu、64G ram broker-a master 10.100.1.22 16 vcpu、64G ram broker-b master 10.100.1.23 16 vcpu、64G ram nameserver、broker-a slave 10.100.1.24 16 vcpu、64G ram nameserver、broker-b-slave 运行环境这次采用的是最新版本4.2.-0-SNAPSHOT，所以jdk需要采用 jdk8 ，按照上一篇文章将jdk全部安装好。 Maven 安装Apache现在并没有提供RocketMQ编译好的版本，所以只能自己下载源码进行编译，由于rocketmq是通过maven进行包管理的，所以要先安装maven。 下载 123jobshen@JobShen-PC:/usr/local$ curl -O http://mirrors.hust.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gzjobshen@JobShen-PC:/usr/local$ tar -zxf apache-maven-3.5.2-bin.tar.gzjobshen@JobShen-PC:/usr/local$ vim apache-maven-3.5.2/conf/settings.xml 修改mirror 镜像源，改为阿里云的镜像： 1234567 &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;external:*,!spring-milestones&lt;/mirrorOf&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 设置环境变量 123456jobshen@JobShen-PC:/usr/local$ vim /etc/profile// 在末尾添加以下内容export M2_HOME=/usr/local/apache-maven-3.5.2/binexport PATH=$M2_HOME/bin:$PATH// 保存 使其生效jobshen@JobShen-PC:/usr/local$ source /etc/profile RocketMQ 编译 克隆代码编译 1234567jobshen@JobShen-PC:/usr/local$ git clone -b develop https://github.com/apache/rocketmq.gitjobshen@JobShen-PC:/usr/local$ cd rocketmqjobshen@JobShen-PC:/usr/local/rocketmq$ mvn -Prelease-all -DskipTests clean install -Ujobshen@JobShen-PC:/usr/local/rocketmq$ cd distribution/targetjobshen@JobShen-PC:/usr/local/rocketmq$ cp apache-rocketmq.tar.gz /usr/local/apache-rocketmq.tar.gzjobshen@JobShen-PC:/usr/local/rocketmq$ cd /usr/localjobshen@JobShen-PC:/usr/local$ tar -zxf apache-rocketmq.tar.gz 将压缩包拷贝到集群中所有机器，并解压 RocketMQ 部署修改目录配置信息 log 日志根目录 store 存储根目录 1jobshen@JobShen-PC:/usr/local$ mkdir -p rocketmq_data/logs rocketmq_data/store 修改日志配置文件中路径 将logback_broker.xml 、logback_filtersrv.xml 、logback_broker.xml、logback_namesrv.xml、logback_tools.xml中的${user.home} 修改为 /usr/local/rocketmq_data 部署NameServer 在10.100.1.23、10.100.1.24两台机器上添加 nameserver 配置文件：nameserver.properties： 12jobshen@JobShen-PC:/usr/local$ mkdir apache-rocketmq/conf/productjobshen@JobShen-PC:/usr/local$ vim apache-rocketmq/conf/product/nameserver.properties 123456789101112rocketmqHome=/usr/local/apache-rocketmqkvConfigPath=/usr/local/rocketmq_data/store/namesrv/kvConfig.jsonlistenPort=9876serverWorkerThreads=16serverCallbackExecutorThreads=0serverSelectorThreads=6serverOnewaySemaphoreValue=512serverAsyncSemaphoreValue=128serverChannelMaxIdleTimeSeconds=240serverSocketSndBufSize=4096serverSocketRcvBufSize=2048serverPooledByteBufAllocatorEnable=false 修改jvm启动参数： 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ vim bin/runserver.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/bin/sh# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the "License"); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#===========================================================================================# Java Environment Setting#===========================================================================================error_exit ()&#123; echo "ERROR: $1 !!" exit 1&#125;[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=$HOME/jdk/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=/usr/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!"export JAVA_HOMEexport JAVA="$JAVA_HOME/bin/java"export BASE_DIR=$(dirname $0)/..export CLASSPATH=.:$&#123;BASE_DIR&#125;/conf:$&#123;CLASSPATH&#125;#===========================================================================================# JVM Configuration#===========================================================================================JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms16g -Xmx16g -Xmn4g -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=1024m -XX:+AlwaysPreTouch -XX:-UseBiasedLocking"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=50m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -verbose:gc -Xloggc:/dev/shm/rmq_srv_gc.log -XX:+PrintGCDetails"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages"JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;JAVA_HOME&#125;/jre/lib/ext:$&#123;BASE_DIR&#125;/lib"#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;"$JAVA $&#123;JAVA_OPT&#125; $@ 制作systemd脚本：namesrv.service 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ vim /lib/systemd/system/namesrv.service 12345678910[Unit]Description=RocketMQ-NameserverAfter=network.target[Service]ExecStart=/usr/local/apache-rocketmq/bin/mqnamesrv -c /usr/local/apache-rocketmq/conf/product/namesrv.propertiesExecStop=/usr/local/apache-rocketmq/bin/mqshutdown namesrv[Install]WantedBy=multi-user.target 12jobshen@JobShen-PC:/usr/local/apache-rocketmq$ ln -s /etc/systemd/system/namesrv.service /lib/systemd/system/namesrv.servicejobshen@JobShen-PC:/usr/local/apache-rocketmq$ systemctl daemon-reload 启动nameserver 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ systemctl start namesrv 部署Broker部署broker-aMaster 在10.100.1.21上新建broker-a-master.properties文件： 12jobshen@JobShen-PC:/usr/local$ mkdir apache-rocketmq/conf/productjobshen@JobShen-PC:/usr/local$ vim apache-rocketmq/conf/product/broker-a-master.properties 123456789101112131415161718192021222324252627282930313233rocketmqHome=/usr/local/apache-rocketmqnamesrvAddr=10.100.1.23:9876;10.100.1.24:9876brokerIP1=10.100.1.21brokerIP2=10.100.1.21brokerName=mq_abrokerClusterName=ProductClusterbrokerId=0defaultTopicQueueNums=16autoCreateTopicEnable=falseclusterTopicEnable=truebrokerTopicEnable=trueautoCreateSubscriptionGroup=truelistenPort=10911storePathRootDir=/usr/local/rocketmq_data/storestorePathCommitLog=/usr/local/rocketmq_data/store/commitlog/storePathConsumerQueue=/usr/local/rocketmq_data/store/consumequeue/mapedFileSizeCommitLog=1073741824mapedFileSizeConsumeQueue=6000000deleteWhen=04diskMaxUsedSpaceRatio=75fileReserverdTime=72haListenPort=10912haSendHeartbeatInterval=5000haHousekeepingInterval=20000haTransferBatchSize=32768haMasterAddress=haSlaveFallbehindMax=268435456brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHsyncFlushTimeout=5000messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2hflushDelayOffsetInterval=10000cleanFileForciblyEnable=true 修改jvm启动参数： 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ vim bin/runbroker.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#!/bin/sh# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the "License"); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#===========================================================================================# Java Environment Setting#===========================================================================================error_exit ()&#123; echo "ERROR: $1 !!" exit 1&#125;[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=$HOME/jdk/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=/usr/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!"export JAVA_HOMEexport JAVA="$JAVA_HOME/bin/java"export BASE_DIR=$(dirname $0)/..export CLASSPATH=.:$&#123;BASE_DIR&#125;/conf:$&#123;CLASSPATH&#125;#===========================================================================================# JVM Configuration#===========================================================================================JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms48g -Xmx48g -Xmn24g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=64m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8"JAVA_OPT="$&#123;JAVA_OPT&#125; -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+AlwaysPreTouch"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=20g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages -XX:-UseBiasedLocking"JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;JAVA_HOME&#125;/jre/lib/ext:$&#123;BASE_DIR&#125;/lib"#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;"numactl --interleave=all pwd &gt; /dev/null 2&gt;&amp;1if [ $? -eq 0 ]then if [ -z "$RMQ_NUMA_NODE" ] ; then numactl --interleave=all $JAVA $&#123;JAVA_OPT&#125; $@ else numactl --cpunodebind=$RMQ_NUMA_NODE --membind=$RMQ_NUMA_NODE $JAVA $&#123;JAVA_OPT&#125; $@ fielse $JAVA $&#123;JAVA_OPT&#125; $@fi 制作systemd脚本：broker.service 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ vim /lib/systemd/system/broker.service 12345678910[Unit]Description=RocketMQ-BrokerAfter=namesrv.service[Service]ExecStart=/usr/local/apache-rocketmq/bin/mqbroker -c /usr/local/apache-rocketmq/conf/product/broker-a-master.propertiesExecStop=/usr/local/apache-rocketmq/bin/mqshutdown broker[Install]WantedBy=multi-user.target 12jobshen@JobShen-PC:/usr/local/apache-rocketmq$ ln -s /etc/systemd/system/broker.service /lib/systemd/system/broker.servicejobshen@JobShen-PC:/usr/local/apache-rocketmq$ systemctl daemon-reload 启动broker 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ systemctl start broker Slave 在10.100.1.23上新建broker-a-slave.properties文件： 12jobshen@JobShen-PC:/usr/local$ mkdir apache-rocketmq/conf/productjobshen@JobShen-PC:/usr/local$ vim apache-rocketmq/conf/product/broker-a-slave.properties 123456789101112131415161718192021222324252627282930313233rocketmqHome=/usr/local/apache-rocketmqnamesrvAddr=10.100.1.23:9876;10.100.1.24:9876brokerIP1=10.100.1.23brokerIP2=10.100.1.23brokerName=mq_abrokerClusterName=ProductClusterbrokerId=1defaultTopicQueueNums=16autoCreateTopicEnable=falseclusterTopicEnable=truebrokerTopicEnable=trueautoCreateSubscriptionGroup=truelistenPort=10911storePathRootDir=/usr/local/rocketmq_data/storestorePathCommitLog=/usr/local/rocketmq_data/store/commitlog/storePathConsumerQueue=/usr/local/rocketmq_data/store/consumequeue/mapedFileSizeCommitLog=1073741824mapedFileSizeConsumeQueue=6000000deleteWhen=04diskMaxUsedSpaceRatio=75fileReserverdTime=72haListenPort=10912haSendHeartbeatInterval=5000haHousekeepingInterval=20000haTransferBatchSize=32768haMasterAddress=haSlaveFallbehindMax=268435456brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHsyncFlushTimeout=5000messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2hflushDelayOffsetInterval=10000cleanFileForciblyEnable=true 修改jvm启动参数： 1jobshen@JobShen-PC:/usr/local/apache-rocketmq$ vim bin/runbroker.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#!/bin/sh# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the "License"); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#===========================================================================================# Java Environment Setting#===========================================================================================error_exit ()&#123; echo "ERROR: $1 !!" exit 1&#125;[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=$HOME/jdk/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=/usr/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!"export JAVA_HOMEexport JAVA="$JAVA_HOME/bin/java"export BASE_DIR=$(dirname $0)/..export CLASSPATH=.:$&#123;BASE_DIR&#125;/conf:$&#123;CLASSPATH&#125;#===========================================================================================# JVM Configuration#===========================================================================================JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms32g -Xmx32g -Xmn16g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=32m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8"JAVA_OPT="$&#123;JAVA_OPT&#125; -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+AlwaysPreTouch"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=15g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages -XX:-UseBiasedLocking"JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;JAVA_HOME&#125;/jre/lib/ext:$&#123;BASE_DIR&#125;/lib"#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;"numactl --interleave=all pwd &gt; /dev/null 2&gt;&amp;1if [ $? -eq 0 ]then if [ -z "$RMQ_NUMA_NODE" ] ; then numactl --interleave=all $JAVA $&#123;JAVA_OPT&#125; $@ else numactl --cpunodebind=$RMQ_NUMA_NODE --membind=$RMQ_NUMA_NODE $JAVA $&#123;JAVA_OPT&#125; $@ fielse $JAVA $&#123;JAVA_OPT&#125; $@fi 和master一样制作systemd 服务并启动 部署broker-b在10.100.1.22上部署master，在10.100.1.24上部署slave，方式和broker-a一样，只需要注意修改ip地址就可以了。 这样，到这里为止，MQ的部署就完成了。]]></content>
      <tags>
        <tag>jdk</tag>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 7下常见中间件环境的安装（一）]]></title>
    <url>%2Fposts%2F3011500279%2F</url>
    <content type="text"><![CDATA[​ 最近由于公司要切换IDC机房，新机房的服务器集群需要重新部署生产环境，于是又趁着这次机会把一些常用的中间件又重新部署了一次，版本有更新，部署方式也会有小变动，于是就有了这一系列的文档。整个系列主要是java运行环境下的中间件部署，也含有少量其他中间件的部署，像 Redis、 TiDB 等。 JDK 安装jdk当然是必不可少的，任何java程序允许都不能脱离JVM环境，而通过jdk安装jvm是最常见的方式，由于一些原因，公司在生产环境并没有使用 open-jdk 而是仍然使用了 oralce-jdk ，因此就不能通过 yum install open-jdk的方式来安装了，只能通过下载 rpm 文件来进行安装。 jdk下载1jobshen@JobShen-PC:/mnt/d/download/softwares$ wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u151-b12/e758a0de34e24606bca991d704f6dcbf/jdk-8u151-linux-x64.rpm" 安装1jobshen@JobShen-PC:/mnt/d/download/softwares$ rpm -ivh jdk-8u151-linux-x64.rpm 配置环境变量1234567jobshen@JobShen-PC:/mnt/d/download/softwares$ vim /etc/profile// 在末尾添加以下内容export JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar// 保存 使其生效jobshen@JobShen-PC:/mnt/d/download/softwares$ source /etc/profile Zookeeper 集群安装集群机器信息 IP Port myid 10.100.1.11 2181 2888 3888 1 10.100.1.12 2181 2888 3888 2 10.100.1.13 2181 2888 3888 3 10.100.1.14 2181 2888 3888 4 10.100.1.15 2181 2888 3888 5 下载1jobshen@JobShen-PC:/mnt/d/download/softwares$ curl -O https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/stable/zookeeper-3.4.10.tar.gz 解压12jobshen@JobShen-PC:/mnt/d/download/softwares$ tar -zxf zookeeper-3.4.10.tar.gz -C /usr/localjobshen@JobShen-PC:/usr/lcoal$ mkdir -p zk_data/zookeeper zk_data/zoo-logs 新建zoo.cfg1jobshen@JobShen-PC:/usr/lcoal$ vim zookeeper-3.4.10/conf/zoo.cfg 1234567891011tickTime=2000initLimit=20syncLimit=10dataDir=/usr/local/zk_data/zookeeperdataLogDir=/usr/local/zk_data/zoo-logsclientPort=2181server.1=10.100.1.11:2888:3888server.2=10.100.1.12:2888:3888server.3=10.100.1.13:2888:3888server.4=10.100.1.14:2888:3888server.5=10.100.1.15:2888:3888 新建myid分别在各台机器上，新建对于myid值的myid文件 12345jobshen@10.100.1.11:/usr/lcoal$ echo "1" &gt; /usr/local/zk_data/zookeeper/myidjobshen@10.100.1.12:/usr/lcoal$ echo "2" &gt; /usr/local/zk_data/zookeeper/myidjobshen@10.100.1.13:/usr/lcoal$ echo "3" &gt; /usr/local/zk_data/zookeeper/myidjobshen@10.100.1.14:/usr/lcoal$ echo "4" &gt; /usr/local/zk_data/zookeeper/myidjobshen@10.100.1.15:/usr/lcoal$ echo "5" &gt; /usr/local/zk_data/zookeeper/myid 制作Systemd脚本1jobshen@10.100.1.11:/usr/lcoal$ vim /lib/systemd/system/zookeeper.service 123456789101112[Unit]Description=zookeeperAfter=network.target[Service]Environment=JAVA_HOME=/usr/java/defaultPIDFile=/usr/local/zk_data/zookeeper/zookeeper_server.pidExecStart=/usr/local/zookeeper-3.4.10/bin/zkServer.sh startExecStop=/usr/local/zookeeper-3.4.10/bin/zkServer.sh stop[Install]WantedBy=multi-user.target 12jobshen@10.100.1.11:/usr/lcoal$ ln -s /etc/systemd/system/zookeeper.service /lib/systemd/system/zookeeper.servicejobshen@10.100.1.11:/usr/lcoal$ systemctl daemon-reload 启动zk集群在各个节点上分别启动zk： 1jobshen@10.100.1.11:/usr/lcoal$ systemctl start zookeeper 检查zk是否启动成功 12jobshen@10.100.1.11:/usr/lcoal$ cd zookeeper-3.4.10/binjobshen@10.100.1.11:/usr/lcoal/zookeeper-3.4.10/bin$ ./zkServer.sh status 输出以下内容即代表启动成功： 123ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower(master) 下篇文章将继续介绍 RocketMQ、 Redis 等集群的安装]]></content>
      <tags>
        <tag>Centos</tag>
        <tag>jdk</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次线上Redis故障恢复和分析（二）]]></title>
    <url>%2Fposts%2F1461710894%2F</url>
    <content type="text"><![CDATA[异常场景最近一段时间时不时就有开发人员向我反应：redis的key有点问题，帮我删个key值、怎么key没有过期，我明明设了过期时间的。一开始没有放心上，以为只是程序逻辑处理不当或者redis偶尔抽风，不用在意。可是渐渐反应的人多了，觉得可能不是这么简单了，于是就和相关的开发人员讨论了下，发现会出现异常的基本是以下两种场景： 使用redis 的 incrBy 命令来防止重复提交，大致的redis交互如下： 123&gt; incrBy key 1 # 返回 1 表示正常 返回 &gt; 1 表示重复提交 直接 return&gt; expire key 5 # 5秒后过期&gt; del key # 正常业务逻辑走完后 显示删除key 使用 redis （set setnx setex ） + expire 组合命令： 12&gt; set |setnx | setex key&gt; expire key seconds # 设置失败 ​ 由于系统中大量使用了第一种方式来防止重复提交，所以这个问题对业务影响还是很大的，redis具体现象为： 设置incrby 第一次应该返回 1 实际上却返回了 2 ，导致业务流程无法走完，并且key没有删除也没有设置过期时间 查找问题编写测试程序为了排查问题写了一个简单的小程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141@Testpublic void test() throws InterruptedException &#123; final List&lt;Long&gt; list = Lists.newArrayListWithCapacity(5000000); Long first_id = 500000000000000001L; for (int i = 0; i &lt; 5000000; i++) &#123; list.add(first_id++); &#125; final CountDownLatch allDone = new CountDownLatch(2); // incrby new Thread( new Runnable() &#123; @Override public void run() &#123; try &#123; testIncrby(list); &#125; catch (InterruptedException e) &#123; &#125; allDone.countDown(); &#125; &#125; ).start(); new Thread( new Runnable() &#123; @Override public void run() &#123; try &#123; testIncrByAndDel(list); &#125; catch (InterruptedException e) &#123; &#125; allDone.countDown(); &#125; &#125; ).start(); allDone.await(); log.info("finish method test");&#125;@Testpublic void testDelAndTTL() throws InterruptedException &#123; final List&lt;Long&gt; list = Lists.newArrayListWithCapacity(5000000); Long first_id = 500000000000000001L; for (int i = 0; i &lt; 5000000; i++) &#123; list.add(first_id++); &#125; final CountDownLatch allDone = new CountDownLatch(2); new Thread( new Runnable() &#123; @Override public void run() &#123; testDelAndTTL(list, "walletMember"); allDone.countDown(); log.info("finish walletMember keys"); &#125; &#125; ).start(); new Thread( new Runnable() &#123; @Override public void run() &#123; testDelAndTTL(list, "walletMember1"); allDone.countDown(); log.info("finish walletMember1 keys"); &#125; &#125; ).start(); allDone.await(); log.info("finish all keys");&#125;private void testIncrby(final List&lt;Long&gt; list) throws InterruptedException &#123; long times = 0L; for(;;)&#123; times ++; for (Long key : list) &#123; Optional&lt;Long&gt; value = redisOperator.incrBy("walletMember" + key, 1); if (value.isPresent()) &#123; if (value.get() != 1L) &#123; log.error("there is something wrong in &#123;&#125;: the incrBy method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrby", 1, value.get(), "walletMember" + key); continue; &#125; &#125; else &#123; log.error("there is something wrong in &#123;&#125;: the incrBy method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrby", 1, null, "walletMember" + key); &#125; Optional&lt;Boolean&gt; isSuccess = redisOperator.expire("walletMember" + key, 30); if (!isSuccess.isPresent() || !isSuccess.get()) &#123; log.error("there is something wrong in &#123;&#125;: the expire method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrby", "true", (isSuccess.isPresent() ? isSuccess.get() : null), "walletMember" + key); &#125; &#125; log.info("finish &#123;&#125; method &#123;&#125; times. sleep 35 seconds", "testIncrby", times); Thread.sleep(60*5*1000L); if(times &gt; 1000000) &#123; return ; &#125; &#125;&#125;private void testIncrByAndDel(final List&lt;Long&gt; list) throws InterruptedException &#123; long times = 0L; for(;;) &#123; times ++; for (Long key : list) &#123; Optional&lt;Long&gt; value = redisOperator.incrBy("walletMember1"+key, 1); if(value.isPresent()) &#123; if(value.get() != 1L) &#123; log.error("there is something wrong in &#123;&#125; method: the incrBy method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrByAndDel", 1, value.get(), "walletMember1" + key); continue; &#125; &#125; else &#123; log.error("there is something wrong in &#123;&#125; method: the incrBy method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrByAndDel", 1, null, "walletMember1" + key); &#125; Optional&lt;Boolean&gt; isSuccess= redisOperator.expire("walletMember"+key, 60); if(!isSuccess.isPresent() || !isSuccess.get()) &#123; log.error("there is something wrong in &#123;&#125;: the expire method return wrong value, expact : &#123;&#125; , result : &#123;&#125;, key : &#123;&#125;", "testIncrByAndDel", "true", (isSuccess.isPresent() ? isSuccess.get() : null), "walletMember1" + key); &#125; redisOperator.del("walletMember1"+key); &#125; log.info("finish &#123;&#125; method &#123;&#125; times. sleep 35 seconds", "testIncrByAndDel", times); Thread.sleep(60*5*1000L); if(times &gt; 1000000) &#123; return ; &#125; &#125;&#125;private void testDelAndTTL(final List&lt;Long&gt; list, String prefix) &#123; for (Long key : list) &#123; Optional&lt;Integer&gt; value = redisOperator.get(prefix + key, Integer.class); if(value.isPresent()) &#123; Long ttl = redisOperator.getFastJsonRedisTemplate().getExpire(prefix + key); log.error("there is something wrong : key : &#123;&#125;, value : &#123;&#125;, ttl : &#123;&#125;", prefix + key, value.get(), ttl); &#125; &#125;&#125; 可能是测试用例写的不好，线上线下都没有发现明显的问题，于是对代码做了调整： 12345678910111213141516171819202122232425262728293031323334353637383940@Autowired private StringRedisTemplate stringRedisTemplate; private static List&lt;String&gt; keys = Lists.newArrayListWithCapacity(100); @RequestMapping(value = "/test/redis", method = RequestMethod.POST) @ResponseBody public String createGoogleAuth() throws InterruptedException &#123; final int numThreads = 100; final ExecutorService threadPool = Executors.newFixedThreadPool(numThreads); log.info("--------------start------------------"); for(int i = 0; i &lt; 100; i++) &#123; threadPool.submit(new Runnable() &#123; @Override public void run() &#123; redis_incrby(); &#125; &#125;); &#125; return "OK"; &#125; private void redis_incrby() &#123; final int loops = 2500; String key = UUID.randomUUID().toString(); keys.add(key); for(int j=0;j&lt;loops;j++) &#123; log.info("key : &#123;&#125;, return : &#123;&#125;", key, stringRedisTemplate.opsForValue().increment(key, 1)); log.info("key : &#123;&#125;, expire : &#123;&#125;", key, stringRedisTemplate.expire(key, 5, TimeUnit.SECONDS)); log.info("key : &#123;&#125;, return : &#123;&#125;", key, stringRedisTemplate.opsForValue().increment(key, 1)); log.info("key : &#123;&#125;, expire : &#123;&#125;", key, stringRedisTemplate.expire(key, 5, TimeUnit.SECONDS)); log.info("key : &#123;&#125;, return : &#123;&#125;", key, stringRedisTemplate.opsForValue().increment(key, 1)); log.info("key : &#123;&#125;, expire : &#123;&#125;", key, stringRedisTemplate.expire(key, 5, TimeUnit.SECONDS)); log.info("key : &#123;&#125;, return : &#123;&#125;", key, stringRedisTemplate.opsForValue().increment(key, 1)); log.info("key : &#123;&#125;, expire : &#123;&#125;", key, stringRedisTemplate.expire(key, 5, TimeUnit.SECONDS)); &#125; stringRedisTemplate.delete(key); log.info("key : &#123;&#125;, finish.", key); &#125; 执行几次后终于发现了问题：按照代码逻辑，每个key最后的value应该都为10000，然后有的key的结果大于10000，于是想到两种情况： 1）客户端多发送了一次命令 2）redis 执行错误 验证原因为了验证到底是哪种原因，采取了以下方式： 修改Jedis 源码：修改BinaryClient的incrBy方法，打印日志信息： 1234public void incrBy(final byte[] key, final long integer) &#123; log.error("key: &#123;&#125;, delta : &#123;&#125;", new String(key), integer); sendCommand(INCRBY, key, toByteArray(integer));&#125; 对redis进行监听，使用watch命令： 1./redis-cli -c -h ip -p port watch 通过tcpdump 对所有流量记录进行保存 1tcpdump -i eth0 -s 0 -w tcp.cap # 保存为.cap文件可以通过wireshark 进行分析 分析原因通过重新执行上面的测试代码，对日志文件进行筛选： 1grep 10001 nohup.out 从中选取一个key：3e9dd73a-fee2-416c-b3c8-5369b2cd4ec8 然后继续筛选： 1grep "key : 3e9dd73a-fee2-416c-b3c8-5369b2cd4ec8 return : " nohup.out 仔细查看后发现： 直接从 2698 跳跃到了 2700 然后再筛选日志，发现以下内容： 连续执行了两次incrBy命令，然后再去查找同一时刻的redis watch记录，发现的确收到了两条INCRBY 3e9dd73a-fee2-416c-b3c8-5369b2cd4ec8 1命令，那接下来就要搞清楚为什么会发起两次请求，于是轮到tcpdump了。 wireshark 分析请求流量将tcpdump的文件导入wireshark后，根据筛选条件进行筛选，最终找到了对应的tcp请求（Frame 698961）： 其中这行引起了我注意：[Expert Info (Note/Sequence): This frame is a (suspected) retransmission] 查询资料后发现，这种情况是出现在以下情形： ​ 当tcp请求允许重试的前提下发现当前tcp请求过了timeout时间还没收到返回值，那么就发起一次重试，而重试的tcp请求在wireshark中就会被标记为[Expert Info (Note/Sequence): This frame is a (suspected) retransmission]。 于是原因很明显了，由于Jedis设置的超时时间过短，导致jedis发起了重试，最终导致了上述redis的异常情况。 解决方案Jedis查询jedis配置文件，发现超时时间为500毫秒， 显然太短了，遂改为15秒，改完以下重新执行了几次测试程序，都没有再发现问题，然后修改线上代码。 Redis导致上述jedis请求超时的原因也有redis cluster的原因。查询发现线上集群存在这key分布不均匀的情况： 可以看出其中一个节点的key数量是其他节点的1.5倍，并且分析这些key发现他们访问的频率也很高，在一定程度上导致了jedis的超时，因此接下来要对redis集群进行优化。]]></content>
      <tags>
        <tag>Redis</tag>
        <tag>Redis Cluster</tag>
        <tag>Jedis</tag>
        <tag>Wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次线上Redis故障恢复和分析（一）]]></title>
    <url>%2Fposts%2F1728650486%2F</url>
    <content type="text"><![CDATA[起因那天早上一到公司就有客服过来反应我们的App登录不了了，我赶紧试了一下登陆App，发现是可以登录的，就以为是个别现象没有在意。过了一会儿客服来反应更频繁了，这才意识到可能没有那么简单。 分析一开始认为是服务器问题，检查了所有相关的应用服务器，应用是否正在运行，发现一切正常，cpu、内存、IO 都是正常的，没有异常； 然后考虑是否是代码层面问题（数据库问题被排除，因为一旦数据库出问题不可能只有一部分人受影响），于是去检查日志，发现有以下错误信息： 然后登陆redis控制台，一台一台测试，终于发现了有问题的那台机器： 接下来要做的就很简单了，redis是集群部署，并且每个节点都有master-slave，因此直接kill该节点，问题修复，一切正常。 寻找根本原因但是这样做并不能解决根本问题，由于之前部署redis集群时考虑不够周全，没有配置redis日志，因此决定直接修改配置文件，逐个重启redis节点。这也就导致了再次故障，因为那个故障节点又被启动加入集群并且由于所有节点都经历了重启该节点又被设为master了。 这时去观察该节点redis的日志，终于发现了问题，满屏都是异常信息： Can’t save in background: fork: Cannot allocate memory 通过Google得知是由于机器内存不足导致的，遂检查机器内存，发现内存已被占用超过90%，于是赶紧增大机器内存，毕竟redis 数据都是存储在内存中，才能做到这么快的读写。 基于此，对整个redis集群的内存占用情况进行了一次排查，增大了机器内存，并且增加了对机器内存使用情况的监控防止再出现此类情况。 又一个问题好景不长，一个问题解决又来一个问题，对于redis操作出现了非预期结果，类似 incrBy +1 结果+2，执行expire 结果返回失败。 该问题的跟踪解决将在下一篇文章中介绍。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Hexo和Github Page搭建个人Blog]]></title>
    <url>%2Fposts%2F3873148614%2F</url>
    <content type="text"><![CDATA[之前使用wordpress在AWS上搭建的博客，但国内访问速度堪忧，而且费用也不少，于是觉得切到Github上，最终觉得通过Hexo和Github Page重新搭建博客，这篇文章只是为了记录搭建的过程，以防以后忘记（记性不好啊。。。） 注册域名并绑定Github Page注册Github和域名就不多说了，网上一搜一大推，接着去Github新建一个仓库，名为个人ID加 github.io，例如我的就是kitdine.github.io: 然后在该仓库下找到一个文件 CNAME， 打开后将里面的值修改为你博客的域名，例如我的 blog.jobshen.com 注册完域名后添加一条CNAME记录，然后解析到github Page的地址，我的域名是在Godaddy上注册，添加一个CNAME指向github.io，像这样： 这样你就可以通过自己的域名访问GitHub Page了。 安装Hexo之所以选择Hexo是因为Hexo看上去非常简洁而且支持Markdown，符合我的期望，安装也很方便。 准备工作Hexo 需要NodeJ.js和git Git Windows：下载并安装 git. Mac：使用 Homebrew, MacPorts ：brew install git;或下载 安装程序 安装。 Linux (Ubuntu, Debian)：sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS)：sudo yum install git-core Node.js安装 Node.js 的最佳方式是使用 nvm。 cURL: 1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh Wget: 1$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js。 1$ nvm install stable 或者您也可以下载 安装程序 来安装。 Windows 用户 对于windows用户来说，建议使用安装程序进行安装。安装时，请勾选Add to PATH选项。另外，您也可以使用Git Bash，这是git for windows自带的一组程序，提供了Linux风格的shell，在该环境下，您可以直接用上面提到的命令来安装Node.js。打开它的方法很简单，在任意位置单击右键，选择“Git Bash Here”即可。由于Hexo的很多操作都涉及到命令行，您可以考虑始终使用Git Bash来进行操作。 安装Hexo所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes _config.yml网站的 配置 信息，您可以在此配置大部分的参数。 package.json应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 1234567891011121314151617181920package.json&#123; "name": "hexo-site", "version": "0.0.0", "private": true, "hexo": &#123; "version": "" &#125;, "dependencies": &#123; "hexo": "^3.0.0", "hexo-generator-archive": "^0.1.0", "hexo-generator-category": "^0.1.0", "hexo-generator-index": "^0.1.0", "hexo-generator-tag": "^0.1.0", "hexo-renderer-ejs": "^0.1.0", "hexo-renderer-stylus": "^0.2.0", "hexo-renderer-marked": "^0.2.4", "hexo-server": "^0.1.2" &#125;&#125; scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。Hexo 会根据主题来生成静态页面。 NexT 主题Hexo 安装主题的方式非常简单，只需要将主题文件拷贝至站点目录的 themes 目录下， 然后修改下配置文件即可。具体到 NexT 来说，安装步骤如下。 下载主题如果你熟悉 Git， 建议你使用 克隆最新版本 的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。 克隆最新版本 在终端窗口下，定位到 Hexo 站点目录下。使用 Git checkout 代码： 12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 启用 NexT 主题 1theme: next 到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 验证主题首先启动 Hexo 本地站点，并开启调试模式（即加上 --debug），整个命令是 hexo s --debug。 在服务启动的过程，注意观察命令行输出是否有任何异常信息，如果你碰到问题，这些信息将帮助他人更好的定位错误。 当命令行输出中提示出： 1INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 此时即可使用浏览器访问 http://localhost:4000，检查站点是否正确运行。 当你看到站点的外观与下图所示类似时即说明你已成功安装 NexT 主题。这是 NexT 默认的 Scheme —— Muse 现在，你已经成功安装并启用了 NexT 主题。下一步我们将要更改一些主题的设定，包括个性化以及集成第三方服务。 更多配置可以访问NexT获取。 写作你可以执行下列命令来创建一篇新文章。 1$ hexo new [layout] &lt;title&gt; 您可以在命令中指定文章的布局（layout），默认为 post，可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局。 布局（Layout）Hexo 有三种默认布局：post、page 和 draft，它们分别对应不同的路径，而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 布局 路径 post source/_posts page source draft source/_drafts 不要处理我的文章 如果你不想你的文章被处理，你可以将 Front-Matter 中的layout: 设为 false 。 文件名称Hexo 默认以标题做为文件名称，但您可编辑 new_post_name 参数来改变默认的文件名称，举例来说，设为 :year-:month-:day-:title.md 可让您更方便的通过日期来管理文章。 变量 描述 :title 标题（小写，空格将会被替换为短杠） :year 建立的年份，比如， 2015 :month 建立的月份（有前导零），比如， 04 :i_month 建立的月份（无前导零），比如， 4 :day 建立的日期（有前导零），比如， 07 :i_day 建立的日期（无前导零），比如， 7 草稿刚刚提到了 Hexo 的一种特殊布局：draft，这种布局在建立时会被保存到 source/_drafts 文件夹，您可通过 publish 命令将草稿移动到 source/_posts 文件夹，该命令的使用方式与 new 十分类似，您也可在命令中指定 layout 来指定布局。 1$ hexo publish [layout] &lt;title&gt; 草稿默认不会显示在页面中，您可在执行时加上 --draft 参数，或是把 render_drafts 参数设为 true来预览草稿。 模版（Scaffold）在新建文章时，Hexo 会根据 scaffolds 文件夹内相对应的文件来建立文件，例如： 1$ hexo new photo &quot;My Gallery&quot; 在执行这行指令时，Hexo 会尝试在 scaffolds 文件夹中寻找 photo.md，并根据其内容建立文章，以下是您可以在模版中使用的变量： 变量 描述 layout 布局 title 标题 date 文件建立日期 生成文件修改 _config.yml 文件： 123# Directorysource_dir: sourcepublic_dir: path/to/your/github/resp # 指向本地仓库，方便提交 使用 Hexo 生成静态文件快速而且简单。 1$ hexo generate 监视文件变动Hexo 能够监视文件变动并立即重新生成静态文件，在生成时会比对文件的 SHA1 checksum，只有变动的文件才会写入。 1$ hexo generate --watch]]></content>
      <tags>
        <tag>Hexo</tag>
        <tag>Github Page</tag>
      </tags>
  </entry>
</search>
